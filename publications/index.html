---
title: Publications from the Fraser Lab
layout: default
group: publications
---
<h1>Publications</h1>
<div class="container-fluid">

    
<br><br>
<br>

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE RA-L</div>
                <img src='/images/IEEE_RA-L.png' alt="sym" width="30%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/10565991">Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination</a></p>
            <p>Lu Wen, H. Eric Tseng, Huei Peng, and Songan Zhang</p>
            <ul>
                <li>We introduce MetaDreamer, a novel context-based Meta Reinforcement Learning (RL) algorithm that addresses the high data and task density requirements of existing Meta RL methods. By leveraging meta-imagination through interpolating learned latent context space and MDP-imagination via a generative world model with added physical knowledge, MetaDreamer significantly improves data efficiency and generalization, outperforming current approaches.</li>
            </ul>
        </div>
    </div>

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE TCST</div>
                <img src='/images/IEEE_TCST_500x300.png' alt="sym" width="40%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/10324408">Safe and Human-Like Autonomous Driving: A Predictorâ€“Corrector Potential Game Approach</a></p>
            <p> Mushuang Liu, H. Eric Tseng, Dimitar Filev, Anouck Girard, and Ilya Kolmanovsky</p>

            <ul>
                <li>We propose PCPG (Predictor-Corrector Potential Game), a novel decision-making framework for autonomous vehicles. PCPG uses a predictor for multi-agent interaction and a corrector to adapt to real-world, unpredictable agent behaviors by measuring and correcting prediction errors. This framework guarantees Nash equilibrium, is computationally scalable, ensures ego-vehicle safety, and approximates true Nash equilibrium despite unknown agent cost functions.</li>
            </ul>
        </div>
    </div>


    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE TITS</div>
                <img src='/images/IEEE_TITS_2025_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/11034670">Bi-Level Transfer Learning for Lifelong-Intelligent Energy Management of Electric Vehicles</a></p>
            <p><strong>Hao Zhang</strong>, Nuo Lei, Wang Peng, Bingbing Li, Shujun Lv, Boli Chen, and Zhi Wang</p>
            <p><a href="https://www.byd.com/us"><strong>Industrial Collaborator: BYD Auto</strong></a> <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong></p>
            <ul>
                <li>We proposed a bi-level transfer approach with MAML to realize cross-platform transferable and online-adaptive EMS for REEVs. It contributed to the successful industry deployment of RL methods, implemented in leading automotive company - BYD Auto, significantly enhancing the REEV efficiency.</li>
            </ul>
        </div>
    </div>


        <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">CVPRW</div>
                <img src='/images/CVPRW_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/9150674">Generating Socially Acceptable Perturbations for Efficient Evaluation of Autonomous Vehicles</a></p>
            <p> S Zhang, H Peng., S Nageshrao, and H. Eric Tseng</p>

            <ul>
                <li>We introduce a novel approach to evaluate the robustness of deep reinforcement learning-based autonomous vehicle (AV) decision-making. We train a "challenger" agent using deep reinforcement learning to generate Socially Acceptable Perturbations (SAPs), aiming to induce crashes where the AV is primarily at fault, even when the AV's policy performs safely in naturalistic environments.</li>
            </ul>
        </div>
    </div>



    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE IROS</div>
                <img src='/images/IEEE_IROS.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/9981621">Improved Robustness and Safety for Pre-Adaptation of Meta Reinforcement Learning with Prior Regularization</a></p>
            <p>Lu Wen, Songan Zhang, H. Eric Tseng, Baljeet Singh, Dimitar Filev, and Huei Peng</p>
            <ul>
                <li>We developed PEARL+, a Meta-Reinforcement Learning algorithm that significantly enhances safety for autonomous systems. Unlike prior methods, PEARL+ explicitly optimizes for pre-adaptation safety and post-adaptation performance in new tasks, showing improved robustness in critical applications.</li>
            </ul>
        </div>
    </div>

        
    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE TITS</div>
                <img src='/images/IEEE_TITS_2025_multi.png' alt="sym" width="20%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://www.techrxiv.org/users/692350/articles/1184096-multi-scale-reinforcement-learning-of-dynamic-energy-controller-for-connected-electrified-vehicles?commit=cd309bc80017f735b83292e39179ef3815d2cbe2">Multi-Scale Reinforcement Learning of Dynamic Energy Controller for Connected Electrified Vehicles</a></p>
            <p><strong>Hao Zhang</strong>, Nuo Lei, Shengbo Eben Li, Junzhi Zhang, Zhi Wang</p>
            <ul>
                <li>This study proposes a multi-horizon reinforcement learning (MHRL) featuring a novel state representation and coordinated training of sub-networks across multiple time scales, which greatly improves fuel economy in real-world driving.</li>
            </ul>
        </div>
    </div>

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">Research</div>
                <img src='/images/LLM_CHENHONG_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://spj.science.org/doi/10.34133/research.0399">Prospective Role of Foundation Models in Advancing Autonomous Vehicles</a></p>
            <p> Jianhua Wu, Bingzhao Gao, Jincheng Gao, Jianhao Yu, HongqingChu, Qiankun Yu, Xun Gong, Yi Chang, H. Eric Tseng, Hong Chen, and Jie Chen</p>
            <ul>
                <li>We present an example of an LLM-driven pipeline for autonomous driving, aiming to advance the application and development of foundation models in the autonomous vehicle domain.</li>
            </ul>
        </div>
    </div>


    

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE SMC</div>
                <img src='/images/IEEE_SMC_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/8914621">Autonomous Highway Driving using Deep Reinforcement Learning</a></p>
            <p>Subramanya Nageshrao, H. Eric Tseng, and Dimitar Filev</p>
            <p><a href="https://www.dongfeng-global.com/"><strong>Industrial Collaborator: Dongfeng Motor</strong></a> <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong></p>
            <ul>
                <li>We proposed a reinforcement learning (RL)-based method where an autonomous vehicle learns to make decisions by interacting directly with simulated traffic, using a deep neural network to select actions for given system states, as demonstrated in highway driving scenarios with varying traffic densities.</li>
            </ul>
        </div>
    </div>

</div>

----------------------------------------------------------------------------------------------------------------------------------------------------------------

<h2>Preprints</h2>
<ul>
    <li>Zhang H, Lei N, Li E S, et al. Multi-scale reinforcement learning of dynamic energy controller for connected electrified vehicles. IEEE Transactions on Intelligent Transportation Systems, 2025, to be published.</li>
    <li>Zhang H, Xu J, Lei N, et al. Surrogate-enhanced multi-objective optimization of on-board hydrogen production device for carbon-free heavy-duty vehicles. Energy, 2025, to be published.</li>
    <li>Li B, Wang K, Zhang H, et al. A Globally Tuned Load-Leveling Strategy for Energy Management of Hybrid Electric Vehicles. Energy, 2025, under review.</li>
</ul>

----------------------------------------------------------------------------------------------------------------------------------------------------------------

<h2>Selected Papers</h2>
<ul>
    <li>Zhang H, Lei N, Chen B, et al. Bi-level transfer learning for lifelong intelligent energy management of electric vehicles. IEEE Transactions on Intelligent Transportation Systems, 2025, Early Access.</li>
    <li>Lei N, Zhang H, Hu J, et al. Sim-to-real design and development of reinforcement learning-based energy management strategies for fuel cell electric vehicles. Applied Energy, 2025,393:126030.</li>
    <li>Lei N, Hao Zhang* (Corresponding), Wang H, et al. Theory-Constrained Neural Network with Modular Interpretability for Fuel Cell Vehicle Modelling. IEEE Trans. on Vehicular Technology, 2025, Early Access.</li>
    <li>Zhang H, Lei N, Chen B, et al. Modeling and control system optimization for electrified vehicles: A data-driven approach. Energy, 2024,311:133196.</li>
    <li>Zhang H, Chen B, Lei N, et al. Coupled velocity and energy management optimization of connected hybrid electric vehicles for maximum collective efficiency. Applied Energy, 2024,360:122792.</li>
    <li>Li B, Zhuang W, Zhang H, et al. Traffic-aware ecological cruising control for connected electric vehicle. IEEE Trans. on Transportation Electrification. 2024,10:5225-5240.</li>
    <li>Zhang H, Chen B, Lei N, et al. Integrated thermal and energy management of connected hybrid electric vehicles using deep reinforcement learning. IEEE Trans. on Transportation Electrification, 2024,10:4594-4603.</li>
    <li>Sun H, Li B, Zhang H, et al. Ecological electric vehicle platooning: an adaptive tube-based distributed model predictive control approach. IEEE Trans. on Transportation Electrification, 2024,11:1048-1060.</li>
    <li>Lei N, Zhang H, Li R, et al. Physics-informed data-driven modeling approach for commuting-oriented hybrid powertrain optimization. Energy Conversion and Management, 2024;299:117814.</li>
    <li>Zhang H, Lei N, Chen B, et al. Data-driven predictive energy consumption minimization strategy for connected plug-in hybrid electric vehicles. Energy, 2023,283:128514.</li>
    <li>Li B, Zhuang W, Zhang H, et al. A comparative study of energy-oriented driving strategy for connected electric vehicles on freeways with varying slopes. Energy, 2023,289:129916.</li>
</ul>
<p>More publications can be found on my <a href="https://scholar.google.com/citations?user=SCHOLAR_ID&user=qC9ScSkAAAAJ">Google Scholar homepage</a>.</p>
