---
title: Publications from the Fraser Lab
layout: default
group: publications
---
<h1>Publications</h1>
<div class="container-fluid">

    
<br><br>
<br>

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE RA-L</div>
                <img src='/images/IEEE_RA-L.png' alt="sym" width="30%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/10565991">Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination</a></p>
            <p>Lu Wen, H. Eric Tseng, Huei Peng, and Songan Zhang</p>
            <ul>
                <li>We introduce MetaDreamer, a novel context-based Meta Reinforcement Learning (RL) algorithm that addresses the high data and task density requirements of existing Meta RL methods. By leveraging meta-imagination through interpolating learned latent context space and MDP-imagination via a generative world model with added physical knowledge, MetaDreamer significantly improves data efficiency and generalization, outperforming current approaches.</li>
            </ul>
        </div>
    </div>

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE TCST</div>
                <img src='/images/IEEE_TCST_500x300.png' alt="sym" width="40%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/10324408">Safe and Human-Like Autonomous Driving: A Predictor–Corrector Potential Game Approach</a></p>
            <p> Mushuang Liu, H. Eric Tseng, Dimitar Filev, Anouck Girard, and Ilya Kolmanovsky</p>

            <ul>
                <li>We propose PCPG (Predictor-Corrector Potential Game), a novel decision-making framework for autonomous vehicles. PCPG uses a predictor for multi-agent interaction and a corrector to adapt to real-world, unpredictable agent behaviors by measuring and correcting prediction errors. This framework guarantees Nash equilibrium, is computationally scalable, ensures ego-vehicle safety, and approximates true Nash equilibrium despite unknown agent cost functions.</li>
            </ul>
        </div>
    </div>


    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE TITS</div>
                <img src='/images/IEEE_TITS_2025_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/11034670">Bi-Level Transfer Learning for Lifelong-Intelligent Energy Management of Electric Vehicles</a></p>
            <p><strong>Hao Zhang</strong>, Nuo Lei, Wang Peng, Bingbing Li, Shujun Lv, Boli Chen, and Zhi Wang</p>
            <p><a href="https://www.byd.com/us"><strong>Industrial Collaborator: BYD Auto</strong></a> <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong></p>
            <ul>
                <li>We proposed a bi-level transfer approach with MAML to realize cross-platform transferable and online-adaptive EMS for REEVs. It contributed to the successful industry deployment of RL methods, implemented in leading automotive company - BYD Auto, significantly enhancing the REEV efficiency.</li>
            </ul>
        </div>
    </div>


        <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">CVPRW</div>
                <img src='/images/CVPRW_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/9150674">Generating Socially Acceptable Perturbations for Efficient Evaluation of Autonomous Vehicles</a></p>
            <p> S Zhang, H Peng., S Nageshrao, and H. Eric Tseng</p>

            <ul>
                <li>We introduce a novel approach to evaluate the robustness of deep reinforcement learning-based autonomous vehicle (AV) decision-making. We train a "challenger" agent using deep reinforcement learning to generate Socially Acceptable Perturbations (SAPs), aiming to induce crashes where the AV is primarily at fault, even when the AV's policy performs safely in naturalistic environments.</li>
            </ul>
        </div>
    </div>



    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE IROS</div>
                <img src='/images/IEEE_IROS.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/9981621">Improved Robustness and Safety for Pre-Adaptation of Meta Reinforcement Learning with Prior Regularization</a></p>
            <p>Lu Wen, Songan Zhang, H. Eric Tseng, Baljeet Singh, Dimitar Filev, and Huei Peng</p>
            <ul>
                <li>We developed PEARL+, a Meta-Reinforcement Learning algorithm that significantly enhances safety for autonomous systems. Unlike prior methods, PEARL+ explicitly optimizes for pre-adaptation safety and post-adaptation performance in new tasks, showing improved robustness in critical applications.</li>
            </ul>
        </div>
    </div>

        
    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE TITS</div>
                <img src='/images/IEEE_TITS_2025_multi.png' alt="sym" width="20%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://www.techrxiv.org/users/692350/articles/1184096-multi-scale-reinforcement-learning-of-dynamic-energy-controller-for-connected-electrified-vehicles?commit=cd309bc80017f735b83292e39179ef3815d2cbe2">Multi-Scale Reinforcement Learning of Dynamic Energy Controller for Connected Electrified Vehicles</a></p>
            <p><strong>Hao Zhang</strong>, Nuo Lei, Shengbo Eben Li, Junzhi Zhang, Zhi Wang</p>
            <ul>
                <li>This study proposes a multi-horizon reinforcement learning (MHRL) featuring a novel state representation and coordinated training of sub-networks across multiple time scales, which greatly improves fuel economy in real-world driving.</li>
            </ul>
        </div>
    </div>

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">Research</div>
                <img src='/images/LLM_CHENHONG_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://spj.science.org/doi/10.34133/research.0399">Prospective Role of Foundation Models in Advancing Autonomous Vehicles</a></p>
            <p> Jianhua Wu, Bingzhao Gao, Jincheng Gao, Jianhao Yu, HongqingChu, Qiankun Yu, Xun Gong, Yi Chang, H. Eric Tseng, Hong Chen, and Jie Chen</p>
            <ul>
                <li>We present an example of an LLM-driven pipeline for autonomous driving, aiming to advance the application and development of foundation models in the autonomous vehicle domain.</li>
            </ul>
        </div>
    </div>


    

    <div class='paper-box'>
        <div class='paper-box-image'>
            <div>
                <div class="badge">IEEE SMC</div>
                <img src='/images/IEEE_SMC_500x300.png' alt="sym" width="100%">
            </div>
        </div>
        <div class='paper-box-text'>
            <p><a href="https://ieeexplore.ieee.org/document/8914621">Autonomous Highway Driving using Deep Reinforcement Learning</a></p>
            <p>Subramanya Nageshrao, H. Eric Tseng, and Dimitar Filev</p>
            <p><a href="https://www.dongfeng-global.com/"><strong>Industrial Collaborator: Dongfeng Motor</strong></a> <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong></p>
            <ul>
                <li>We proposed a reinforcement learning (RL)-based method where an autonomous vehicle learns to make decisions by interacting directly with simulated traffic, using a deep neural network to select actions for given system states, as demonstrated in highway driving scenarios with varying traffic densities.</li>
            </ul>
        </div>
    </div>

</div>

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

<h2>Book Chapter</h2>
<ul>
    <li>Tseng, H. E. (2015). Vehicle Dynamics Control. In Encyclopedia of Systems and Control (ISBN: 978-1-4471-5057-2, pp. 1517–1524). </li>
    <li>Hrovat, D., Tseng, H. E., Di Cairano, S., & Annaswamy, A. (2014). Addressing Automotive Industry Needs with Model Predictive Control. In Impact of Control Technology, 2nd Edition (ISBN: 978-0-692-24262-9). IEEE Control Systems Society.</li>
    <li>Geering, H. P. (2010). Linear Parameter-Varying Control of Nonlinear Systems with Applications to Automotive and Aerospace Controls. In The Control Handbook, Second Edition: Control System Applications, Second Edition (pp. 1--1). CRC Press.</li>
    <li>Falcone, P., Borrelli, F., Tseng, E. H., & Hrovat, D. (2010). On low complexity predictive approaches to control of autonomous vehicles. In Automotive Model Predictive Control (Vol. 402, pp. 195–210). Springer London. </li>
</ul>

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

<h2>Selected Journal Papers</h2>
<ul>
    <li>X. Li, K. Liu, H. E. Tseng, A. Girard and I. Kolmanovsky, "Decision-Making for Autonomous Vehicles With Interaction-Aware Behavioral Prediction and Social-Attention Neural Network," in IEEE Transactions on Control Systems Technology, Early Access.</li>
    <li>S. H. Nair, H. Lee, E. Joa, Y. Wang, H. E. Tseng and F. Borrelli, "Predictive Control for Autonomous Driving With Uncertain, Multimodal Predictions," in IEEE Transactions on Control Systems Technology, Early Access.</li>
    <li>Zhang H, Lei N, Li E S, et al. Multi-scale reinforcement learning of dynamic energy controller for connected electrified vehicles. IEEE Transactions on Intelligent Transportation Systems, 2025, to be published.</li>
    <li>M. Liu, H. Eric Tseng, D. Filev, A. Girard and I. Kolmanovsky, "Game Projection and Robustness for Game-Theoretic Autonomous Driving," in IEEE Transactions on Intelligent Transportation Systems, vol. 26, no. 3, pp. 3446-3457, 2025.</li>
    <li>Zhang H, Lei N, Chen B, et al. Bi-level transfer learning for lifelong intelligent energy management of electric vehicles. IEEE Transactions on Intelligent Transportation Systems, 2025, Early Access.</li>
    <li>Lei N, Hao Zhang*, Wang H, et al. Theory-Constrained Neural Network with Modular Interpretability for Fuel Cell Vehicle Modelling. IEEE Trans. on Vehicular Technology, 2025, Early Access.</li>
    <li>L. Wen, E. H. Tseng, H. Peng and S. Zhang, "Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination," in IEEE Robotics and Automation Letters, vol. 9, no. 11, pp. 9701-9708, Nov. 2024.</li>
    <li>Jianhua Wu, Bingzhao Gao, Jincheng Gao, Jianhao Yu, Hongqing Chu, Qiankun Yu, Xun Gong, Yi Chang, H. Eric Tseng, Hong Chen, et al. Prospective Role of Foundation Models in Advancing Autonomous Vehicles. Research. 2024;7:0399.</li>
    <li>Oh, S., Chen, Q., Tseng, H. E., Pandey, G., & Orosz, G. Sharable clothoid-based continuous motion planning for connected automated vehicles. 1–15. </li>   
    <li>Zhang H, Lei N, Chen B, et al. Modeling and control system optimization for electrified vehicles: A data-driven approach. Energy, 2024,311:133196.</li>
    <li>Zhang H, Chen B, Lei N, et al. Coupled velocity and energy management optimization of connected hybrid electric vehicles for maximum collective efficiency. Applied Energy, 2024,360:122792.</li>
    <li>Li B, Zhuang W, Zhang H, et al. Traffic-aware ecological cruising control for connected electric vehicle. IEEE Trans. on Transportation Electrification. 2024,10:5225-5240.</li>
    <li>Zhang H, Chen B, Lei N, et al. Integrated thermal and energy management of connected hybrid electric vehicles using deep reinforcement learning. IEEE Trans. on Transportation Electrification, 2024,10:4594-4603.</li>
    <li>Sun H, Li B, Zhang H, et al. Ecological electric vehicle platooning: an adaptive tube-based distributed model predictive control approach. IEEE Trans. on Transportation Electrification, 2024,11:1048-1060.</li>
    <li>Lei N, Zhang H, Li R, et al. Physics-informed data-driven modeling approach for commuting-oriented hybrid powertrain optimization. Energy Conversion and Management, 2024;299:117814.</li>
    <li>Zhang H, Lei N, Chen B, et al. Data-driven predictive energy consumption minimization strategy for connected plug-in hybrid electric vehicles. Energy, 2023,283:128514.</li>
    <li>Yu, H., Tseng, H. E., & Langari, R. A human-like game theory-based controller for automatic lane changing. Transportation Research Part C: Emerging Technologies, 88, 140–158. </li>
    <li>Ranogajec, V., Ivanović, V., Deur, J., & Tseng, H. E. Optimization-based assessment of automatic transmission double-transition shift controls. Control Engineering Practice. 76, 155–166. </li>
    <li>Annaswamy, A. M., Guan, Y., Tseng, H. E., Zhou, H., Phan, T., & Yanakiev, D. Transactive control in smart cities. Proceedings of the IEEE, 106(4), 518–537.</li>
    <li>Sun H, Li B, Zhang H, et al. Ecological electric vehicle platooning: an adaptive tube-based distributed model predictive control approach. IEEE Trans. on Transportation Electrification, 2024,11:1048-1060.</li>
    <li>Deur, J., Milutinović, M., Ivanović, V., & Tseng, H. E. (2016). Modeling of a dry dual clutch utilizing a lever-based electromechanical actuator. Journal of Dynamic Systems, Measurement, and Control, 138(9), 091012.</li>   
</ul>


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

<h2>Selected Conference Papers</h2>
<ul>
    <li>L. Wen, S. Zhang, H. E. Tseng, B. Singh, D. Filev and H. Peng, "Improved Robustness and Safety for Pre-Adaptation of Meta Reinforcement Learning with Prior Regularization," IEEE IROS, 2022. </li>
    <li>S. Zhang, L. Wen, H. Peng, and H. E. Tseng. "Quick learner automated vehicle adapting its roadmanship to varying traffic cultures with meta reinforcement learning." In IEEE ITSC, 2021. </li>
    <li>Zhang, S., Peng, H., Nageshrao, S., & Eric Tseng, H. (2020). Generating Socially Acceptable Perturbations for Efficient Evaluation of Autonomous Vehicles. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (2020 CVPRW)</li>
    <li>Nageshrao, S., Tseng, H. E., & Filev, D. Autonomous highway driving using deep reinforcement learning. In 2019 IEEE SMC</li>
    <li>Zhang, S., Peng, H., Zhao, D., & Tseng, H. E.. Accelerated evaluation of autonomous vehicles in the lane change scenario based on subset simulation technique. 2018 21st International Conference on Intelligent Transportation Systems (ITSC), 3935–3940. </li>
    <li>Zhang, Q., Filev, D., Tseng, H. E., Szwabowski, S., & Langari, R.. Addressing mandatory lane change problem with game theoretic model predictive control and fuzzy Markov chain. 2018 Annual American Control Conference (ACC), 4764–4771.</li>
    <li>Lee, S., & Tseng, H. E. (2018). Trajectory planning with shadow trolleys for an autonomous vehicle on bending roads and switchbacks. 2018 IEEE Intelligent Vehicles Symposium (IV), 484–489.  </li>
    <li>Liu, C., Lee, S., Varnhagen, S., & Tseng, H. E.. Path planning for autonomous vehicles using model predictive control. 2017 IEEE Intelligent Vehicles Symposium (IV), 174–179. </li>
    <li>Bujarbaruah, M., Ercan, Z., Ivanovic, V., Tseng, H. E., & Borrelli, F.. Torque-based lane change assistance with active front steering. 2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC), 1–6.</li>
    <li>Xu, L., Tseng, H. E., & Hrovat, D.. Hybrid model predictive control of active suspension with travel limits and nonlinear tire contact force. 2016 American Control Conference (ACC), 2415–2420.</li>
    <li>Velazquez Alcantar, J., Assadian, F., Kuang, M., & Tseng, E.. Optimal longitudinal slip ratio allocation and control of a hybrid electric vehicle with eawd capabilities. Dynamic Systems and Control Conference, 50701, V002T30A002.</li>
    <li>Ercan, Z., Carvalho, A., Lefevre, S., Gokasan, M., Tseng, H. E., & Borrelli, F.. Torque-based steering assistance for collision avoidance during lane changes. Advanced Vehicle Control: Proceedings of the 13th International Symposium on Advanced Vehicle Control.  </li>
    <li>Gao, Y., Gray, A., Carvalho, A., Tseng, H. E., & Borrelli, F.. Robust nonlinear predictive control for semiautonomous ground vehicles. 2014 American Control Conference, 4913–4918.</li>
    <li>Turri, V., Carvalho, A., Tseng, H. E., Johansson, K. H., & Borrelli, F.. Linear model predictive control for lane keeping and obstacle avoidance on low curvature roads. 16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013), 378–383.  </li>
    <li>Lin, T., Tseng, E., & Borrelli, F.. Modeling driver behavior during complex maneuvers. 2013 American Control Conference, 6448–6453.</li>
</ul>
<br><br>


<p>More publications and patents can be found on Prof. Tseng's <a href="https://scholar.google.com/citations?user=UWnwlu4AAAAJ">Google Scholar homepage</a>.</p>
